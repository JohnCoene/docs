---
title: "bibler"
author: "John Coene"
date: "9 May 2016"
output:
  html_document:
    theme: yeti
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 9)
library(bibler)
library(plotly)
library(tm)
library(wordcloud)
```

## Overview

Bibler includes 6 neat datasets about the King James Bible and the Apocrypha, all are documented.

### Bible

* `king_james_df` The King James Bible as data.frame
* `king_james_tm` The King James Bible as [tm](https://cran.r-project.org/package=tm) corpus (`c("VCorpus", "Corpus"`)
* `king_james_books` List of books that constitute the King James Bible

### Apocrypha

* `apocrypha_df` The Apocrypha as data.frame
* `apocrypha_tm` The Apocrypha as [tm](https://cran.r-project.org/package=tm) corpus (`c("VCorpus", "Corpus"`)
* `apocrypha_books` List of books that constitute the Apocrypha

### Utils

* `middle_english_stopwords` Character vector of Middle English stopwords
* `middle_english_positive` Lexicon of positive Middle English terms
* `middle_english_negative` Lexicon of negative Middle English terms

## Install

Install development version from [github](https://github.com/JohnCoene/bibler).

```{r, eval=FALSE}
devtools::install_github("JohnCoene/bibler")
library(bibler)
```

## Datasets

Both the `data.frame` and `Corpus` (tm) datasets include the following variables:

* `Book.Abbreviation`
* `King.James.Bible` - book title as in King James Bible
* `Vulgate` - book title as in Vulgate
* `Douay.Rheims` - book title in Douay Reihms version
* `Full.Title.Auth.V` - book title in authorized version
* `Testament` - Testament in which book/verse can be found.
* `Book.Number` - Order of appearance of books, starting with Genesis #1
* `Verse`
* `Text` - content of verse

In the corpus datasets (ending in `_tm`) each verse makes a document while in the `data.frame` each row is a verse.

```{r}
library(tm)
length(king_james_tm) == nrow(king_james_df)
```

### data.frame

The data frames consist of one verse by row, meta-data are variables.

```{r}
names(king_james_df) # see ?king_james_df
```

### Corpus

The [tm](https://cran.r-project.org/package=tm) corpus is comprised of `r length(king_james_tm)` documents, one for each verse and include meta-data (variables in `_df` dataset).

```{r}
meta(king_james_tm[[1]])
```

### Books

Reference list of the books included in datasets.

```{r}
knitr::kable(head(king_james_books, 5), format = "html")
```

## Text Exploration

### Term Frequency

We can have a look at the most mentioned terms in the Bible. Here I use the `king_james_tm` dataset which is a corpus of documents from the [tm](https://cran.r-project.org/package=tm) package. 

```{r}
library(wordcloud)
library(tm)
data("king_james_tm")
```

`bibler` also comes with a set of `r data("middle_english_stopwords"); length(middle_english_stopwords)` Middle English stopwords.

```{r}
data("middle_english_stopwords") # get middle english stopwords

# clean text
wc <- tm_map(king_james_tm, tolower) # to lower case
wc <- tm_map(wc, stripWhitespace)
wc <- tm_map(wc, removeNumbers) # remove #
wc <- tm_map(wc, removePunctuation) # remove punctuation
wc <- tm_map(wc, removeWords, c(stopwords("english"), middle_english_stopwords,
                                "lord", "god")) # remove stopwords
wc <- tm_map(wc, PlainTextDocument)

# count term frequency
tdm <- TermDocumentMatrix(wc, control = list(minWordLength = 2))
tdm <- removeSparseTerms(tdm, 0.99) 
tdm <- as.matrix(tdm)
tdm <- sort(rowSums(tdm), decreasing = TRUE)
dat <- data.frame(word = names(tdm), freq = tdm)

# wordcloud
wordcloud(words = dat$word, scale = c(4, .3), freq = dat$freq, max.words = 100,
          rot.per = 0.25, 
          colors = c("#bce784", "#5dd39e", "#348aa7", "#525174", "#513b56"))
```

```{r, echo=FALSE}
rm(wc)
rm(tdm)
```

### Sentiment Analysis

First we can download the well-known Bing Liu lists of positive and negative terms.

* [Hu and Liu Lexicons](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar)

```{r, warning=FALSE, eval=FALSE}
# base Bing Liu lexicons
neg <- readLines(paste0("https://raw.githubusercontent.com/JohnCoene/", 
                        "docs/master/negative-words.txt"))
neg <- neg[36:length(neg)]
pos <- readLines(paste0("https://raw.githubusercontent.com/JohnCoene/", 
                        "docs/master/positive-words.txt"))
pos <- pos[36:length(pos)]
```

```{r, warning=FALSE, eval=TRUE, echo=FALSE}
# base Bing Liu lexicons
neg <- readLines(paste0("negative-words.txt"))
neg <- neg[36:length(neg)]
pos <- readLines(paste0("positive-words.txt"))
pos <- pos[36:length(pos)]
```

However those lexicons are based on Internet reviews and other modernities and therefore are not well suited to the King James Bible. To remedy to this `bibler` also comes with lexicons of positive and negative Middle English terms.

* `r length(middle_english_positive)` Positive terms
* `r length(middle_english_negative)` Negative terms

```{r, warning=FALSE}
data("middle_english_negative")
data("middle_english_positive")
head(middle_english_negative) # inspect
```

```{r}
# bind all terms
pos <- c(pos, middle_english_positive)
neg <- c(neg, middle_english_negative)
```

We can now assess the sentiment of each verse and plot the average sentiment by book in order of appearance in the Bible.

```{r, warning=FALSE, fig_width = 8}
# sentiment scoring FUN
sentiment_score = function(text, pos.words, neg.words){
  scores = plyr::laply(text,
                 function(text, pos.words, neg.words){
                   text = gsub("[[:punct:]]", "", text)
                   text = gsub("[[:cntrl:]]", "", text)
                   text = gsub('\\d+', '', text)
                   text = sapply(text, tolower)
                   word_list = stringr::str_split(text, "\\s+")
                   words = unlist(word_list)
                   positive_matches = match(words, pos.words)
                   negative_matches = match(words, neg.words)
                   positive_matches = !is.na(positive_matches)
                   negative_matches = !is.na(negative_matches)
                   score = sum(positive_matches) - sum(negative_matches)
                   return(score)
                 }, pos.words, neg.words)
  return(scores)
}

# score each verse
king_james_df$Sentiment <- sentiment_score(king_james_df$Text, pos, neg)

# mean sentiment / book
bks <- plyr::ddply(king_james_df, c("King.James.Bible", "Book.Number"),
                                    plyr::summarise, Sentiment = mean(Sentiment))

bks$colour <- ifelse(bks$Sentiment >= 0, "#bce784", "#348aa7")
bks$label <- ifelse(bks$Sentiment >= 0, "positive", "negative")
plot_ly(bks,
        x = Book.Number,
        y = Sentiment,
        type = "bar",
        text = King.James.Bible,
        hoverinfo = text,
        color = label,
        marker = list(
          color = colour
        )) %>%
  layout(title = "Average sentiment by book",
         showlegend = FALSE,
         xaxis = list(title = "Book Number"),
         width = 800,
         height = 415)
```

There is indeed more negativity at the "begining" of the Bible: the Old Testament is far more gruesome than the New Testament. The *Song of Solomon* is a lapse of light amidst the dark and spine-chilling godly injunctions of the Old Testament, it is scripturally unique in its celebration of sexual love. John 3 in the New Testament is also positive, by the Bible standard anyway: John accepts Jesus as the Messiah, gets baptised, finds the path to God, etc. Good stuff. The most negative book according to the analysis is Zephaniah which is not inaccurate, the message of the book is best summed by this terse and unambiguous passage:

> "You also, O Ethiopians, / Shall be killed by my sword."

Zephaniah comes towards the end of the Old Testament and those who have not accepted the truth by then must be slain.
  
```{r, warning = FALSE}
library(ggplot2)

rect <- data.frame(xmin = c(0, 39), xmax = c(39, 67), ymin = c(-1.1, -1.1), 
                   ymax = c(1.5, 1.5), 
                   label = c("Old Testament", "New Testament"),
                   fill = c("#bce784", "#348aa7"))

ggplot(data = bks, aes(x = Book.Number, y = Sentiment)) +
    geom_rect(data = rect, 
              aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
                  fill = fill, alpha = 0.5),
            inherit.aes = FALSE,
            position = "identity") +
  geom_text(data = rect, aes(x = c(39/2, (39+(27/2))), y = ymax - 0.2, 
                             label = label),
            color = "grey20", fontface = "bold", size = 4) +
  geom_bar(stat = "identity", fill = "grey50") + 
  scale_fill_manual(values = c("#bce784", "#348aa7")) +
  theme(legend.position = "none",
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())
```

Average sentiment:

* Old Testament: `r mean(king_james_df[king_james_df$Testament == "Old Testament",]$Sentiment)`
* New Testament: `mean(king_james_df[king_james_df$Testament == "New Testament",]$Sentiment)`

### Testaments

Since there are textual differences between Testaments we'll categorise the verses according to each and plot a comparison cloud.

```{r}
# split
old <- paste0(king_james_df[king_james_df$Testament == "Old Testament", "Text"],
              collapse = "")
new <- paste0(king_james_df[king_james_df$Testament == "New Testament", "Text"],
              collapse = "")
corp <- Corpus(VectorSource(c(old, new))) # combine
```

```{r}
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, content_transformer(tolower))
corp <- tm_map(corp, removeNumbers)
corp <- tm_map(corp, removeWords, c(middle_english_stopwords, 
                                    stopwords("english")))

term.matrix <- TermDocumentMatrix(corp)
term.matrix <- as.matrix(term.matrix)
colnames(term.matrix) <- c("Old Testament", "New Testament")
comparison.cloud(term.matrix, max.words = 200, random.order = FALSE,
                 rot.per = 0.25, colors = c("#bce784", "#348aa7"), title.size = 1, 
                 scale = c(3, .5))
```

The New Testament is mostly about Jesus Christ and the band of disciples roaming the lands laying hands. While the Old Testament is more about God appearing to illiterate desert people ruling that *thee* and *thy* shall obey.

### Mary

Christopher Hitchens once said that Mary only appeared three times in the bibe. I cannot tell exactly what he meants by "appeared" (only God knows now) but we can tell that she is mentioned far more often - `r length(king_james_df$Text[grep("Mary", king_james_df$Text)])` times.


```{r}
length(king_james_df$Text[grep("Mary[[:space:]]|Mary[[:punct:]]", king_james_df$Text)]) # nbr mentions
king_james_df$Text[grep("Mary[[:space:]]|Mary[[:punct:]]", king_james_df$Text)][1] # First appearance in Bible
```

### Abraham

What about Abraham? If the willingness to kill your own child gets you in the Bible surely it should get you mentioned in here.

```{r}
length(grep("Abraham", king_james_df$Text))
```

## Disclaimer

1. In the event that the above has not made it obvious; I am not an expert in text mining or natural language processing, let alone Middle English.
2. Yes, this is an opinionated piece.